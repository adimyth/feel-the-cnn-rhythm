{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ad973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98baa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glorious-totem-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/sharad30/feel-the-cnn-rhythm\" target=\"_blank\">https://wandb.ai/sharad30/feel-the-cnn-rhythm</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/sharad30/feel-the-cnn-rhythm/runs/2lytta2x\" target=\"_blank\">https://wandb.ai/sharad30/feel-the-cnn-rhythm/runs/2lytta2x</a><br/>\n",
       "                Run data is saved locally in <code>/jupyter/notebooks/wandb/run-20210821_194452-2lytta2x</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8759414da4d74e4cb96b64bf50909372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/171M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type   | Params\n",
      "---------------------------------------------\n",
      "0 | feature_extractor | ResNet | 44.5 M\n",
      "1 | classifier        | Linear | 2.0 K \n",
      "---------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "44.5 M    Non-trainable params\n",
      "44.6 M    Total params\n",
      "178.205   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19826dc520e4d1e8aada9df277680a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.functional.classification.accuracy.accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92443e1000ba492d82b01dd353dceb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1c2d7bb99f4351948f5e59000ab1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models  # type:ignore\n",
    "import wandb  # type:ignore\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder  # type:ignore\n",
    "from torchvision.ops import sigmoid_focal_loss  # type:ignore\n",
    "\n",
    "\n",
    "class FTRDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int = 64, data_dir: str = \"\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # preprocessing steps applied to data\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(size=256),\n",
    "                transforms.CenterCrop(size=224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        ftr_dataset = ImageFolder(self.data_dir)\n",
    "\n",
    "        num_train = int(0.75 * len(ftr_dataset))\n",
    "        num_valid = int(0.15 * len(ftr_dataset))\n",
    "        num_test = len(ftr_dataset) - num_train - num_valid\n",
    "\n",
    "        # split dataset\n",
    "        self.train, self.val, self.test = random_split(ftr_dataset, [num_train, num_valid, num_test])\n",
    "        self.train.dataset.transform = self.transform\n",
    "        self.val.dataset.transform = self.transform\n",
    "        self.test.dataset.transform = self.transform\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True, num_workers=12)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size, num_workers=12)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, num_workers=12)\n",
    "\n",
    "\n",
    "class FTRModel(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_classes: int = 2, learning_rate: float = 1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        # log hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dim = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.feature_extractor = models.resnet101(pretrained=True)\n",
    "        # layers are frozen by using eval()\n",
    "        self.feature_extractor.eval()\n",
    "        # freeze params\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        n_sizes = self._get_conv_output(input_shape)\n",
    "\n",
    "        self.classifier = nn.Linear(n_sizes, num_classes)\n",
    "\n",
    "    # returns the size of the output tensor going into the Linear layer from the conv block\n",
    "    def _get_conv_output(self, shape):\n",
    "        batch_size = 1\n",
    "        tmp_input = torch.autograd.Variable(torch.rand(batch_size, *shape))\n",
    "\n",
    "        output_feat = self._forward_features(tmp_input)\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\n",
    "        return n_size\n",
    "\n",
    "    # returns the feature tensor from the conv block\n",
    "    def _forward_features(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        return x\n",
    "\n",
    "    # will be used during inference\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.log_softmax(self.classifier(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # logic for a single training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # logits = F.softmax_loss(logits)\n",
    "        # loss = sigmoid_focal_loss(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # logic for a single validation step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # logits = F.softmax_loss(logits)\n",
    "        # loss = sigmoid_focal_loss(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # logic for a single testing step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "\n",
    "        # logits = F.softmax_loss(logits)\n",
    "        # loss = sigmoid_focal_loss(logits, y)\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datamodule = FTRDataModule(batch_size=512, data_dir=\"/data\")\n",
    "    datamodule.setup()\n",
    "\n",
    "    # wandb.login()\n",
    "    wandb.init(project=\"feel-the-cnn-rhythm\", entity=\"sharad30\")\n",
    "    wandb_logger = WandbLogger(project=\"ftr-lightning\", job_type=\"train\")\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=False, mode=\"min\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=\"experiments\",\n",
    "        filename=\"model/model-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=3,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    model = FTRModel((3, 64, 64), 2)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=20,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        gpus=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.test()\n",
    "\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f68966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0+cu102'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eea293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addbf5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
